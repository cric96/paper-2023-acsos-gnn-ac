% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2018/03/10
%
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage[T1]{fontenc}
\usepackage{xcolor}
\def\doi#1{\href{https://doi.org/\detokenize{#1}}{\url{https://doi.org/\detokenize{#1}}}}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}
%
\usepackage{listings}
\lstset{language=Pascal}
\begin{document}
%
\title{Field-informed Reinforcement Learning for Learnining Large Scale Collective Tasks} %% Todo improve
% or: Field-Informed Reinforcement Learning: A Scalable and Effective Method for Collective Intelligence
% or: A Novel Approach to Reinforcement Learning for Adaptive Collective Systems
%

\author{
\IEEEauthorblockN{Gianluca Aguzzi}
\IEEEauthorblockA{
%\textit{Department of Computer Science and Engineering} \\
\textit{%Alma Mater Studiorum--
University of Bologna}\\
Cesena, Italy\\
gianluca.aguzzi@unibo.it
}

\and
%\linebreakand %\and
\IEEEauthorblockN{Mirko Viroli}
\IEEEauthorblockA{
%\textit{Department of Computer Science and Engineering} \\
\textit{%Alma Mater Studiorum--
University of Bologna}\\
Cesena, Italy\\
mirko.viroli@unibo.it % 0000−0003−2702−5702
}
\and
\IEEEauthorblockN{Lukas Esterle}
\IEEEauthorblockA{
%\textit{Department of Computer Science and Engineering} \\
\textit{%Alma Mater Studiorum--
Aarhus University}\\
Aarhus, Denmark\\
lukas.esterle@ece.au.dk}
}
%
\maketitle              % typeset the header of the contribution
%

%%% Comment command, to be removed before submission
\newcommand{\meta}[3]{\textcolor{#1}{\textbf{#2}: #3}}
\newcommand{\ga}[1]{\meta{red}{GA}{#1}}
\newcommand{\lukas}[1]{\meta{purple}{Lukas}{#1}}
\newcommand{\mv}[1]{\meta{green}{MV}{#1}}
\ga{Page limit: 10 pages (include refs)}


\begin{abstract}
Coordinatinating a group of intelligent agents in multi-agent systems 
 is a research problem that has been addressed for a long time, 
 due to the challenges posed by distribution and of the definition of distributed intelligence. 
%
The problem is even more evident in collective adaptive systems, 
 where the scale of the systems considered makes the definition of collective behaviors even more challenging. 

In this paper we consider a new reinforcement learning approach 
  for the definition of intelligent agents called \emph{Field-Informed reinforcement learning}, 
  where we use computational \emph{computational fields} to manage the interaction between agents 
  in stigmergically and Graph Neural Networks to learn a local behaviour necessary to solve collective tasks. 
%
This allows us to create distributed controllers informed by a collective knowledge 
 distilled during learning but that use only local information at runtime.
% 
We demonstrate the effectiveness of this new approach in several case studies 
 where coordination tasks are successfully solved. \lukas{do we really have multiple case studies?} 
\end{abstract}

\begin{IEEEkeywords}
aggregate computing, Graph Neural Network, Cyber-Physical Swarms.
\end{IEEEkeywords}
%
\section{Introduction}
Various phenomena in the real world are not evenly distributed across the environment such as watershed, wild fires, traffic, human crowd movement, or wild life movement from insects, fish, birds, and mammals.
To acquire appropriate information about such phenomena, we also need to distribute the sensors accordingly to cover all aspects sufficiently. While manual deployment will mitigate the problem, not all phenomena are known exactly \emph{a priori} and would require maintenance and adjustment during runtime. Even worse, with phenomena able to change their location, size, and distribution---as it is the case with crowds, wild life, or wild fires---an adaptation of the collective sensors is required in order to keep the required information. 

This leads to several questions 
\begin{enumerate}
	\item How to distribute sensors to ensure good attainment of information?
	\item How to maintain knowledge about the phenomena and unlearn irrelevant information?
	\item How to move sensors when the phenomena moves to ensure good coverage?
\end{enumerate} \lukas{refine and rework these questions}

In this paper, we propose a novel approach combining aggregate computing
~\cite{Beal2015Computer} with Graph Neural Networks
~\cite{Zhou2020AIOpen} to focus on the relevant areas. We further combine this with reinforcement learning techniques to respond to changing conditions in the environment.
Specifically, we will show... \lukas{more info...}

The remainder of this paper is structured as follows. First we introduce the relevant background and problem formulation. Afterwards we introduce our approach in Section~\ref{sec:approach}. Section~\ref{sec:eval} outlines the performed experiments and discusses the obtained results. Finally, we will present our conclusions in Section~\ref{sec:conclusion}.

\section{Background}
\label{sec:background}
\ga{Page budget: 1 page}

\section{Background and Motivation}
\ga{Page budget: 1 page}
\ga{Plan: discussed the problem of coordination in multi-agent systems 
and the need for a scalable approach. In doing this, we will discuss some of the existing approaches}
\subsection{Field Coordination Approaches}
\subsection{Many-Agent Reinforcement Learning}
\subsection{Graph Neural Network}


\section{Field-informed Reinforcement Learning}

\section{Approach}
\label{sec:approach}

\section{Evaluation}
\label{sec:eval}
\subsection{Simulation setup}
\subsection{Scenario}

\paragraph*{Variant A}
\paragraph*{Variant B}
\paragraph*{Variant C}

\section{Conclusion and Future Work}
\label{sec:conclusion}

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}
